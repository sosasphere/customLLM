{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3f4784-1928-4a8d-bccf-7d4b5566bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.1\n",
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446e3118-f2b6-4f5e-a2fb-3c7e784a82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5556b6-b29d-489f-91c7-1332856ad62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item]\n",
    "print(preprocessed[:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e985e8-80db-45cc-88d9-2d28051dfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 8405\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\", len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba26753b-d11e-4b9b-aafd-2666a240838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90212e6f-04ad-4766-9f54-d5917666d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386edc31-7d00-4894-bef0-af7a05378f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n', 0)\n",
      "(' ', 1)\n",
      "('!', 2)\n",
      "('\"', 3)\n",
      "(\"'\", 4)\n",
      "('(', 5)\n",
      "(')', 6)\n",
      "(',', 7)\n",
      "('--', 8)\n",
      "('.', 9)\n",
      "(':', 10)\n",
      "(';', 11)\n",
      "('?', 12)\n",
      "('A', 13)\n",
      "('Ah', 14)\n",
      "('Among', 15)\n",
      "('And', 16)\n",
      "('Are', 17)\n",
      "('Arrt', 18)\n",
      "('As', 19)\n",
      "('At', 20)\n",
      "('Be', 21)\n",
      "('Begin', 22)\n",
      "('Burlington', 23)\n",
      "('But', 24)\n",
      "('By', 25)\n",
      "('Carlo', 26)\n",
      "('Chicago', 27)\n",
      "('Claude', 28)\n",
      "('Come', 29)\n",
      "('Croft', 30)\n",
      "('Destroyed', 31)\n",
      "('Devonshire', 32)\n",
      "('Don', 33)\n",
      "('Dubarry', 34)\n",
      "('Emperors', 35)\n",
      "('Florence', 36)\n",
      "('For', 37)\n",
      "('Gallery', 38)\n",
      "('Gideon', 39)\n",
      "('Gisburn', 40)\n",
      "('Gisburns', 41)\n",
      "('Grafton', 42)\n",
      "('Greek', 43)\n",
      "('Grindle', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486f4375-7552-4813-9ce2-7962a535e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d3b384-2461-4dc6-ba71-83127dd5d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 58, 4, 852, 990, 604, 535, 748, 7, 1128, 598, 7, 3, 69, 9, 40, 853, 1110, 756, 795, 9]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4777ee76-e7c8-4f20-bfc5-338bd2416995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a08b202-9a8f-49ac-b244-689906ea3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759e9bcd-5778-4f2f-9ea7-c8ac076bb588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818dc54f-eac9-46b1-ab74-bf2eab75dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a8ffe6-bd18-441b-acba-b838b6ecd4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58d9928-5793-4f7e-8ae2-a8f5b2a611b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a386abbb-ff50-4dd2-8f6f-ba9f23c37062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.1\n",
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ec20b1-7a0a-43ea-93e4-2c8880c53dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e04a3a36-f6d3-4b3f-9f7c-debee58e55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from supplementary import TransformerBlock, LayerNorm\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cc8230d-7e47-4ace-baa5-de82b55e13f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0e8d420-d7a4-41b4-80d7-97fccb74d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 6.4164e-02,  2.0443e-01, -1.6945e-01,  ...,  1.7887e-01,\n",
      "           2.1921e-01, -5.8153e-01],\n",
      "         [ 3.7736e-01, -4.2545e-01, -6.5874e-01,  ..., -2.5050e-01,\n",
      "           4.6553e-01, -2.5760e-01],\n",
      "         [ 8.8996e-01, -1.3770e-01,  1.4748e-01,  ...,  1.7770e-01,\n",
      "          -1.2015e-01, -1.8902e-01],\n",
      "         [-9.7276e-01,  9.7338e-02, -2.5419e-01,  ...,  1.1035e+00,\n",
      "           3.7639e-01, -5.9006e-01]],\n",
      "\n",
      "        [[ 6.4164e-02,  2.0443e-01, -1.6945e-01,  ...,  1.7887e-01,\n",
      "           2.1921e-01, -5.8153e-01],\n",
      "         [ 1.3433e-01, -2.1289e-01, -2.7020e-02,  ...,  8.1153e-01,\n",
      "          -4.7410e-02,  3.1186e-01],\n",
      "         [ 8.9996e-01,  9.5396e-01, -1.7896e-01,  ...,  8.3053e-01,\n",
      "           2.7657e-01, -2.4577e-02],\n",
      "         [-9.3326e-05,  1.9390e-01,  5.1217e-01,  ...,  1.1915e+00,\n",
      "          -1.6431e-01,  3.7046e-02]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2108ab7-c62a-40d5-a6f4-a3a882c8e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8425097-9414-4419-aae0-99584eca3cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1578a837-9cfd-4d86-9713-5818298ad54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from supplementary import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269d92b9-a23b-456f-9aad-1cb8ad4bfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from supplementary import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48da2195-b177-4e29-bf29-2e3a0c2fc3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82642379-a21a-451d-a639-cac86641927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "031e63aa-f1c0-4fbe-a5e4-d8c364e7d78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "049bc3ce-1311-4082-98ca-f285cd53d28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2766344-02f7-4830-82f1-d7cd221d08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d1bfbde-95cd-4869-b84b-2eb21ceffd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24668b72-ab74-4f30-a8b1-8cda6cd6e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aff83daf-48d4-41bc-86eb-93de306a0e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "from supplementary import calc_loss_loader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21c42eaf-3ab6-4645-b6e5-b87f1e083516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import (\n",
    "    calc_loss_batch,\n",
    "    evaluate_model,\n",
    "    generate_and_print_sample\n",
    ")\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7025afc-c18a-43e2-9512-3aa6b65a9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0304478-3c1c-4c29-83bd-78505de1451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "341327d9-7312-48da-905b-0b5ed28fddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from supplementary import plot_losses\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9400713e-56c6-4a50-8cb6-58ca76d18efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"What is Worldpay?\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer).to(device),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6e78a47-2128-46eb-9b61-a0daeb313c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " What is Worldpay? It was not that my hostess was \"interesting\n"
     ]
    }
   ],
   "source": [
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d506a8da-65bd-4d51-a836-d69c6218cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cf0b4b1-1544-45a2-a327-88f66e225aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.66.6\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cb7d4c2-8542-479f-aa93-c44077e2c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative import from the gpt_download.py contained in this folder\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ddf5050-2d43-4ef8-a062-c8f7d8bf7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 37.8kiB/s]\n",
      "encoder.json: 100%|███████████████████████████████████████████████████████████████| 1.04M/1.04M [00:01<00:00, 756kiB/s]\n",
      "hparams.json: 100%|████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 43.6kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|███████████████████████████████████████████████| 498M/498M [09:13<00:00, 899kiB/s]\n",
      "model.ckpt.index: 100%|██████████████████████████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 2.65MiB/s]\n",
      "model.ckpt.meta: 100%|██████████████████████████████████████████████████████████████| 471k/471k [00:00<00:00, 893kiB/s]\n",
      "vocab.bpe: 100%|████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 537kiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "132f4a94-8ebc-4b28-9c46-b8890b0c1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10bfe4dc-04ae-4e89-849f-7fdb12004f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b24c1a2-c68e-4cff-80e4-f389118fe23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba2c73-6496-418e-8140-f4909b95f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a314c2-e52e-447c-8b94-8094f5a5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import GPTModel\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad437bb-7b1d-4e03-93ff-41d096561824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532c7e9-9221-4e95-ba37-68c6abe13561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from supplementary import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
